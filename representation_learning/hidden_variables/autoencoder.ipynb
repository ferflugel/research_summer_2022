{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "original_dimension = 3\n",
    "encoded_dimension = 2\n",
    "\n",
    "# create the layers of the model\n",
    "input_vector = keras.Input(shape=(original_dimension,))\n",
    "encoded = layers.Dense(encoded_dimension, activation='relu')(input_vector)\n",
    "decoded = layers.Dense(original_dimension, activation='sigmoid')(encoded)\n",
    "\n",
    "# create the model mapping the input and its reconstruction\n",
    "autoencoder = keras.Model(input_vector, decoded)\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# create a model for the encoder\n",
    "encoder = keras.Model(input_vector, encoded)\n",
    "\n",
    "# and one for the decoder\n",
    "encoded_input = keras.Input(shape=(encoded_dimension,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# now we compile the model with the optimizer and loss\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        h_1       h_2       x_1       x_2       x_3  y\n0 -0.507907 -0.426783 -0.348796 -0.156770 -0.197266  0\n1  0.208406  0.579240 -0.049915 -0.135873 -0.057563  1\n2 -0.408581  0.486722 -0.734377 -0.359439 -0.515557  1\n3 -0.686362  0.810403 -0.127156  0.049691 -0.722663  1\n4 -0.270678  0.418167 -0.747838 -0.360587 -0.447434  1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h_1</th>\n      <th>h_2</th>\n      <th>x_1</th>\n      <th>x_2</th>\n      <th>x_3</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.507907</td>\n      <td>-0.426783</td>\n      <td>-0.348796</td>\n      <td>-0.156770</td>\n      <td>-0.197266</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208406</td>\n      <td>0.579240</td>\n      <td>-0.049915</td>\n      <td>-0.135873</td>\n      <td>-0.057563</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.408581</td>\n      <td>0.486722</td>\n      <td>-0.734377</td>\n      <td>-0.359439</td>\n      <td>-0.515557</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.686362</td>\n      <td>0.810403</td>\n      <td>-0.127156</td>\n      <td>0.049691</td>\n      <td>-0.722663</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.270678</td>\n      <td>0.418167</td>\n      <td>-0.747838</td>\n      <td>-0.360587</td>\n      <td>-0.447434</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read synthetic data\n",
    "data = pd.read_csv('datasets/real_life_regressor.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 0.7064 - val_loss: 0.7029\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6972 - val_loss: 0.6940\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6884 - val_loss: 0.6853\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6798 - val_loss: 0.6770\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6715 - val_loss: 0.6688\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.6609\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6556 - val_loss: 0.6532\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6456\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6403 - val_loss: 0.6382\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6329 - val_loss: 0.6309\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6256 - val_loss: 0.6237\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6185 - val_loss: 0.6166\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6115 - val_loss: 0.6097\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6045 - val_loss: 0.6027\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5976 - val_loss: 0.5958\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5908 - val_loss: 0.5889\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5839 - val_loss: 0.5820\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5772 - val_loss: 0.5751\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5704 - val_loss: 0.5683\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5638 - val_loss: 0.5613\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5569 - val_loss: 0.5544\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5500 - val_loss: 0.5473\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5430 - val_loss: 0.5402\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5360 - val_loss: 0.5329\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5287 - val_loss: 0.5256\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5215 - val_loss: 0.5179\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5140 - val_loss: 0.5101\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5061 - val_loss: 0.5021\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4984 - val_loss: 0.4934\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4899 - val_loss: 0.4844\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4806 - val_loss: 0.4749\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4708 - val_loss: 0.4645\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4598 - val_loss: 0.4537\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4485 - val_loss: 0.4423\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4368 - val_loss: 0.4304\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4247 - val_loss: 0.4185\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4123 - val_loss: 0.4066\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3997 - val_loss: 0.3945\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3873 - val_loss: 0.3822\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - val_loss: 0.3697\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3615 - val_loss: 0.3574\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3487 - val_loss: 0.3447\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3355 - val_loss: 0.3321\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3223 - val_loss: 0.3196\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3093 - val_loss: 0.3068\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2959 - val_loss: 0.2942\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2828 - val_loss: 0.2813\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2691 - val_loss: 0.2687\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2558 - val_loss: 0.2560\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2426 - val_loss: 0.2431\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2290 - val_loss: 0.2304\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2156 - val_loss: 0.2176\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2020 - val_loss: 0.2048\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1885 - val_loss: 0.1919\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1750 - val_loss: 0.1790\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1616 - val_loss: 0.1661\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1476 - val_loss: 0.1537\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1344 - val_loss: 0.1407\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1205 - val_loss: 0.1278\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.1150\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.1020\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0890\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0760\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0629\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0497\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0363\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0227\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0065 - val_loss: 0.0090\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0212 - val_loss: -0.0052\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0364 - val_loss: -0.0195\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: -0.0519 - val_loss: -0.0336\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0671 - val_loss: -0.0482\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0828 - val_loss: -0.0626\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.0986 - val_loss: -0.0770\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.1142 - val_loss: -0.0916\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.1301 - val_loss: -0.1062\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.1458 - val_loss: -0.1209\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.1618 - val_loss: -0.1355\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.1773 - val_loss: -0.1503\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.1934 - val_loss: -0.1648\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.2091 - val_loss: -0.1794\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.2249 - val_loss: -0.1938\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.2406 - val_loss: -0.2082\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.2564 - val_loss: -0.2224\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.2719 - val_loss: -0.2369\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.2874 - val_loss: -0.2515\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.3034 - val_loss: -0.2659\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.3191 - val_loss: -0.2804\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.3352 - val_loss: -0.2947\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.3509 - val_loss: -0.3091\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.3668 - val_loss: -0.3236\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.3827 - val_loss: -0.3381\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.3985 - val_loss: -0.3529\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.4148 - val_loss: -0.3676\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.4308 - val_loss: -0.3823\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.4474 - val_loss: -0.3966\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.4630 - val_loss: -0.4117\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.4796 - val_loss: -0.4266\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.4961 - val_loss: -0.4415\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.5127 - val_loss: -0.4564\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.5292 - val_loss: -0.4715\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.5458 - val_loss: -0.4868\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.5628 - val_loss: -0.5019\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.5797 - val_loss: -0.5174\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.5965 - val_loss: -0.5332\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.6141 - val_loss: -0.5485\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.6311 - val_loss: -0.5644\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.6490 - val_loss: -0.5797\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.6661 - val_loss: -0.5957\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.6838 - val_loss: -0.6117\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.7018 - val_loss: -0.6275\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.7195 - val_loss: -0.6438\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.7376 - val_loss: -0.6600\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.7556 - val_loss: -0.6766\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.7741 - val_loss: -0.6932\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.7923 - val_loss: -0.7101\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.8113 - val_loss: -0.7266\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.8298 - val_loss: -0.7435\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.8487 - val_loss: -0.7605\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.8676 - val_loss: -0.7778\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.8865 - val_loss: -0.7954\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.9063 - val_loss: -0.8124\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.9255 - val_loss: -0.8299\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.9450 - val_loss: -0.8475\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -0.9648 - val_loss: -0.8652\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.9845 - val_loss: -0.8833\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.0051 - val_loss: -0.9011\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.0248 - val_loss: -0.9197\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.0454 - val_loss: -0.9381\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.0657 - val_loss: -0.9567\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.0866 - val_loss: -0.9754\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.1078 - val_loss: -0.9938\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.1286 - val_loss: -1.0126\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.1495 - val_loss: -1.0317\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.1710 - val_loss: -1.0506\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.1921 - val_loss: -1.0700\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.2135 - val_loss: -1.0896\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.2354 - val_loss: -1.1089\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.2572 - val_loss: -1.1285\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.2791 - val_loss: -1.1482\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.3014 - val_loss: -1.1679\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.3235 - val_loss: -1.1880\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.3460 - val_loss: -1.2083\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -1.3688 - val_loss: -1.2286\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.3916 - val_loss: -1.2490\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.4144 - val_loss: -1.2698\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.4374 - val_loss: -1.2910\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.4615 - val_loss: -1.3115\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.4843 - val_loss: -1.3328\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.5082 - val_loss: -1.3539\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.5322 - val_loss: -1.3750\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.5559 - val_loss: -1.3965\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.5801 - val_loss: -1.4181\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.6046 - val_loss: -1.4397\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.6287 - val_loss: -1.4619\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.6533 - val_loss: -1.4842\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.6783 - val_loss: -1.5062\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.7030 - val_loss: -1.5285\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.7276 - val_loss: -1.5513\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.7534 - val_loss: -1.5736\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.7788 - val_loss: -1.5961\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.8042 - val_loss: -1.6188\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.8294 - val_loss: -1.6421\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.8560 - val_loss: -1.6647\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.8812 - val_loss: -1.6882\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.9073 - val_loss: -1.7117\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -1.9338 - val_loss: -1.7349\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.9601 - val_loss: -1.7584\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -1.9871 - val_loss: -1.7817\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.0130 - val_loss: -1.8062\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.0403 - val_loss: -1.8304\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.0675 - val_loss: -1.8545\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.0948 - val_loss: -1.8786\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.1218 - val_loss: -1.9031\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.1492 - val_loss: -1.9277\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.1766 - val_loss: -1.9526\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.2051 - val_loss: -1.9767\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.2324 - val_loss: -2.0016\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.2598 - val_loss: -2.0272\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.2886 - val_loss: -2.0523\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.3172 - val_loss: -2.0771\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.3453 - val_loss: -2.1026\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.3734 - val_loss: -2.1288\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.4028 - val_loss: -2.1542\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.4314 - val_loss: -2.1799\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.4607 - val_loss: -2.2054\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.4892 - val_loss: -2.2317\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.5188 - val_loss: -2.2577\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.5485 - val_loss: -2.2837\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.5775 - val_loss: -2.3102\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.6070 - val_loss: -2.3368\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.6372 - val_loss: -2.3631\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.6671 - val_loss: -2.3898\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.6968 - val_loss: -2.4173\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.7278 - val_loss: -2.4440\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.7575 - val_loss: -2.4716\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.7890 - val_loss: -2.4984\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.8190 - val_loss: -2.5260\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.8504 - val_loss: -2.5532\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.8812 - val_loss: -2.5809\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -2.9120 - val_loss: -2.6091\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.9441 - val_loss: -2.6363\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -2.9748 - val_loss: -2.6644\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.0058 - val_loss: -2.6932\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.0380 - val_loss: -2.7215\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.0698 - val_loss: -2.7497\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.1018 - val_loss: -2.7777\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.1327 - val_loss: -2.8068\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.1659 - val_loss: -2.8350\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.1975 - val_loss: -2.8638\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.2302 - val_loss: -2.8924\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.2629 - val_loss: -2.9210\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.2949 - val_loss: -2.9503\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.3278 - val_loss: -2.9795\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.3609 - val_loss: -3.0088\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.3939 - val_loss: -3.0382\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.4268 - val_loss: -3.0682\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.4608 - val_loss: -3.0974\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.4933 - val_loss: -3.1279\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.5276 - val_loss: -3.1577\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.5618 - val_loss: -3.1870\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.5941 - val_loss: -3.2181\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.6291 - val_loss: -3.2481\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.6632 - val_loss: -3.2783\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.6966 - val_loss: -3.3091\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.7320 - val_loss: -3.3388\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.7652 - val_loss: -3.3701\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.8007 - val_loss: -3.4006\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.8346 - val_loss: -3.4321\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.8706 - val_loss: -3.4626\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.9054 - val_loss: -3.4932\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -3.9394 - val_loss: -3.5254\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -3.9752 - val_loss: -3.5571\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -4.0107 - val_loss: -3.5887\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.0464 - val_loss: -3.6201\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.0815 - val_loss: -3.6517\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.1179 - val_loss: -3.6826\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.1525 - val_loss: -3.7145\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.1885 - val_loss: -3.7466\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.2246 - val_loss: -3.7788\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.2607 - val_loss: -3.8109\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.2963 - val_loss: -3.8437\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.3331 - val_loss: -3.8759\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -4.3700 - val_loss: -3.9074\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.4051 - val_loss: -3.9405\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.4429 - val_loss: -3.9724\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.4790 - val_loss: -4.0056\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.5164 - val_loss: -4.0385\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: -4.5529 - val_loss: -4.0718\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.5901 - val_loss: -4.1052\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.6283 - val_loss: -4.1376\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.6646 - val_loss: -4.1711\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.7028 - val_loss: -4.2041\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.7397 - val_loss: -4.2382\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.7786 - val_loss: -4.2712\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.8154 - val_loss: -4.3055\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.8542 - val_loss: -4.3387\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.8916 - val_loss: -4.3728\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.9302 - val_loss: -4.4065\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -4.9686 - val_loss: -4.4403\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.0068 - val_loss: -4.4749\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.0456 - val_loss: -4.5094\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.0847 - val_loss: -4.5436\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.1232 - val_loss: -4.5783\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.1619 - val_loss: -4.6134\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.2007 - val_loss: -4.6485\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.2404 - val_loss: -4.6830\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.2797 - val_loss: -4.7176\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.3190 - val_loss: -4.7524\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.3582 - val_loss: -4.7877\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.3980 - val_loss: -4.8229\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.4380 - val_loss: -4.8576\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.4769 - val_loss: -4.8935\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.5179 - val_loss: -4.9283\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.5570 - val_loss: -4.9639\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.5962 - val_loss: -5.0005\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.6377 - val_loss: -5.0360\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.6775 - val_loss: -5.0718\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.7177 - val_loss: -5.1077\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.7591 - val_loss: -5.1429\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.7986 - val_loss: -5.1797\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -5.8396 - val_loss: -5.2163\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.8807 - val_loss: -5.2528\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.9226 - val_loss: -5.2885\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -5.9634 - val_loss: -5.3248\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.0044 - val_loss: -5.3614\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.0450 - val_loss: -5.3990\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -6.0870 - val_loss: -5.4358\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.1287 - val_loss: -5.4727\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.1711 - val_loss: -5.5092\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.2123 - val_loss: -5.5467\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.2541 - val_loss: -5.5846\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.2967 - val_loss: -5.6221\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -6.3390 - val_loss: -5.6595\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.3813 - val_loss: -5.6968\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -6.4242 - val_loss: -5.7337\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.4653 - val_loss: -5.7722\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.5085 - val_loss: -5.8104\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.5517 - val_loss: -5.8482\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.5946 - val_loss: -5.8859\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.6362 - val_loss: -5.9249\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.6808 - val_loss: -5.9622\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.7233 - val_loss: -6.0004\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.7650 - val_loss: -6.0402\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.8100 - val_loss: -6.0782\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.8533 - val_loss: -6.1166\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -6.8967 - val_loss: -6.1554\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -6.9408 - val_loss: -6.1938\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -6.9837 - val_loss: -6.2331\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.0281 - val_loss: -6.2720\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.0726 - val_loss: -6.3105\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.1164 - val_loss: -6.3493\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.1592 - val_loss: -6.3898\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.2048 - val_loss: -6.4289\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.2490 - val_loss: -6.4684\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.2936 - val_loss: -6.5075\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.3369 - val_loss: -6.5479\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.3831 - val_loss: -6.5865\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.4274 - val_loss: -6.6256\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.4715 - val_loss: -6.6657\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.5170 - val_loss: -6.7055\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.5611 - val_loss: -6.7465\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.6071 - val_loss: -6.7866\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.6519 - val_loss: -6.8270\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.6976 - val_loss: -6.8666\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.7424 - val_loss: -6.9068\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.7879 - val_loss: -6.9472\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.8334 - val_loss: -6.9879\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.8800 - val_loss: -7.0278\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -7.9246 - val_loss: -7.0688\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -7.9717 - val_loss: -7.1091\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.0175 - val_loss: -7.1502\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -8.0629 - val_loss: -7.1925\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.1098 - val_loss: -7.2338\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.1565 - val_loss: -7.2746\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.2030 - val_loss: -7.3152\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.2496 - val_loss: -7.3560\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.2949 - val_loss: -7.3980\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.3420 - val_loss: -7.4396\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.3899 - val_loss: -7.4802\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.4357 - val_loss: -7.5222\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.4825 - val_loss: -7.5643\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.5298 - val_loss: -7.6062\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.5778 - val_loss: -7.6474\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.6243 - val_loss: -7.6897\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.6721 - val_loss: -7.7316\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -8.7191 - val_loss: -7.7744\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -8.7669 - val_loss: -7.8168\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.8143 - val_loss: -7.8594\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -8.8627 - val_loss: -7.9013\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -8.9109 - val_loss: -7.9427\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -8.9579 - val_loss: -7.9853\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.0061 - val_loss: -8.0280\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.0539 - val_loss: -8.0713\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.1021 - val_loss: -8.1146\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.1510 - val_loss: -8.1571\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.1989 - val_loss: -8.2001\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.2484 - val_loss: -8.2425\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.2966 - val_loss: -8.2855\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.3447 - val_loss: -8.3294\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.3941 - val_loss: -8.3733\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.4437 - val_loss: -8.4165\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.4929 - val_loss: -8.4599\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.5417 - val_loss: -8.5040\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.5911 - val_loss: -8.5482\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.6411 - val_loss: -8.5917\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.6904 - val_loss: -8.6355\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.7398 - val_loss: -8.6797\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.7897 - val_loss: -8.7239\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.8406 - val_loss: -8.7673\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -9.8886 - val_loss: -8.8135\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.9402 - val_loss: -8.8577\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -9.9898 - val_loss: -8.9026\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.0411 - val_loss: -8.9461\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.0904 - val_loss: -8.9911\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.1415 - val_loss: -9.0357\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.1920 - val_loss: -9.0801\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.2422 - val_loss: -9.1249\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.2924 - val_loss: -9.1706\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.3441 - val_loss: -9.2155\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.3941 - val_loss: -9.2613\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.4459 - val_loss: -9.3062\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.4974 - val_loss: -9.3505\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.5474 - val_loss: -9.3958\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.5975 - val_loss: -9.4422\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.6509 - val_loss: -9.4867\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.7011 - val_loss: -9.5329\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.7532 - val_loss: -9.5791\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -10.8049 - val_loss: -9.6256\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.8585 - val_loss: -9.6700\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.9085 - val_loss: -9.7169\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -10.9600 - val_loss: -9.7642\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.0141 - val_loss: -9.8093\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.0656 - val_loss: -9.8554\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.1169 - val_loss: -9.9027\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.1706 - val_loss: -9.9483\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.2220 - val_loss: -9.9951\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.2754 - val_loss: -10.0411\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.3266 - val_loss: -10.0887\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.3799 - val_loss: -10.1359\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.4339 - val_loss: -10.1819\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.4865 - val_loss: -10.2286\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.5390 - val_loss: -10.2761\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.5933 - val_loss: -10.3227\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.6468 - val_loss: -10.3694\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.6990 - val_loss: -10.4181\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.7526 - val_loss: -10.4664\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.8082 - val_loss: -10.5122\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.8597 - val_loss: -10.5607\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -11.9134 - val_loss: -10.6090\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -11.9685 - val_loss: -10.6558\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.0210 - val_loss: -10.7045\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.0758 - val_loss: -10.7525\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.1299 - val_loss: -10.8001\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.1839 - val_loss: -10.8476\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.2374 - val_loss: -10.8958\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.2929 - val_loss: -10.9431\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.3467 - val_loss: -10.9910\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.4000 - val_loss: -11.0403\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.4560 - val_loss: -11.0884\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.5108 - val_loss: -11.1366\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.5633 - val_loss: -11.1871\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.6217 - val_loss: -11.2339\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.6745 - val_loss: -11.2829\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.7290 - val_loss: -11.3323\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.7846 - val_loss: -11.3809\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -12.8403 - val_loss: -11.4289\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.8948 - val_loss: -11.4780\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -12.9499 - val_loss: -11.5273\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -13.0059 - val_loss: -11.5764\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.0611 - val_loss: -11.6262\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.1174 - val_loss: -11.6754\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.1736 - val_loss: -11.7246\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -13.2294 - val_loss: -11.7745\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.2852 - val_loss: -11.8248\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.3430 - val_loss: -11.8730\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.3978 - val_loss: -11.9232\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.4538 - val_loss: -11.9740\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.5111 - val_loss: -12.0239\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -13.5656 - val_loss: -12.0755\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.6241 - val_loss: -12.1254\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -13.6814 - val_loss: -12.1743\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.7365 - val_loss: -12.2248\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.7943 - val_loss: -12.2747\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.8507 - val_loss: -12.3257\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -13.9078 - val_loss: -12.3768\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -13.9660 - val_loss: -12.4271\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.0229 - val_loss: -12.4780\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.0802 - val_loss: -12.5292\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.1371 - val_loss: -12.5808\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.1950 - val_loss: -12.6324\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.2540 - val_loss: -12.6827\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.3108 - val_loss: -12.7339\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.3685 - val_loss: -12.7853\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.4268 - val_loss: -12.8366\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.4854 - val_loss: -12.8870\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.5423 - val_loss: -12.9387\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -14.6010 - val_loss: -12.9903\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.6588 - val_loss: -13.0425\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.7182 - val_loss: -13.0937\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.7759 - val_loss: -13.1459\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.8348 - val_loss: -13.1983\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.8929 - val_loss: -13.2513\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -14.9532 - val_loss: -13.3022\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.0116 - val_loss: -13.3540\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.0710 - val_loss: -13.4053\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.1288 - val_loss: -13.4583\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.1883 - val_loss: -13.5112\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.2473 - val_loss: -13.5647\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -15.3082 - val_loss: -13.6165\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.3677 - val_loss: -13.6687\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -15.4271 - val_loss: -13.7220\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.4869 - val_loss: -13.7754\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.5471 - val_loss: -13.8281\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.6065 - val_loss: -13.8816\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.6663 - val_loss: -13.9351\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.7276 - val_loss: -13.9878\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.7863 - val_loss: -14.0420\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.8479 - val_loss: -14.0951\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -15.9080 - val_loss: -14.1480\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -15.9686 - val_loss: -14.2009\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.0287 - val_loss: -14.2550\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.0882 - val_loss: -14.3101\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.1508 - val_loss: -14.3628\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.2118 - val_loss: -14.4153\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.2693 - val_loss: -14.4714\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.3329 - val_loss: -14.5248\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.3928 - val_loss: -14.5794\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.4554 - val_loss: -14.6323\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.5154 - val_loss: -14.6865\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.5767 - val_loss: -14.7413\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.6389 - val_loss: -14.7955\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.7001 - val_loss: -14.8506\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.7620 - val_loss: -14.9050\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.8232 - val_loss: -14.9599\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.8850 - val_loss: -15.0144\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -16.9467 - val_loss: -15.0690\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -17.0074 - val_loss: -15.1245\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -17.0702 - val_loss: -15.1791\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: -17.1337 - val_loss: -15.2319\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fbcba258af0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and validation set\n",
    "observations = data[['x_1', 'x_2', 'x_3']]\n",
    "training_set = observations.iloc[:750, :].to_numpy()\n",
    "validation_set = observations.iloc[750:, :].to_numpy()\n",
    "\n",
    "# and now we train the autoencoder\n",
    "autoencoder.fit(training_set, training_set,\n",
    "                epochs=500,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(validation_set, validation_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "          h_1       h_2       x_1       x_2       x_3  y        z_1       z_2\n0   -0.507907 -0.426783 -0.348796 -0.156770 -0.197266  0  12.530251  0.000000\n1    0.208406  0.579240 -0.049915 -0.135873 -0.057563  1   9.211573  0.470352\n2   -0.408581  0.486722 -0.734377 -0.359439 -0.515557  1  19.174109  0.000000\n3   -0.686362  0.810403 -0.127156  0.049691 -0.722663  1  14.096041  0.000000\n4   -0.270678  0.418167 -0.747838 -0.360587 -0.447434  1  18.695078  0.000000\n..        ...       ...       ...       ...       ... ..        ...       ...\n995 -0.459596 -0.513566 -0.230339 -0.197124 -0.142681  0  11.552031  0.000000\n996  0.353899  0.330092  0.481501  0.140985  0.080699  1   2.614529  1.803656\n997 -0.221661 -0.488341  0.028726 -0.115426 -0.013636  0   8.176119  0.698690\n998 -0.308154  0.301733 -0.730905 -0.398765 -0.322134  1  17.780859  0.000000\n999  0.197770 -0.689366  0.340792  0.040297  0.541430  0   0.337498  1.559129\n\n[1000 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h_1</th>\n      <th>h_2</th>\n      <th>x_1</th>\n      <th>x_2</th>\n      <th>x_3</th>\n      <th>y</th>\n      <th>z_1</th>\n      <th>z_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.507907</td>\n      <td>-0.426783</td>\n      <td>-0.348796</td>\n      <td>-0.156770</td>\n      <td>-0.197266</td>\n      <td>0</td>\n      <td>12.530251</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208406</td>\n      <td>0.579240</td>\n      <td>-0.049915</td>\n      <td>-0.135873</td>\n      <td>-0.057563</td>\n      <td>1</td>\n      <td>9.211573</td>\n      <td>0.470352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.408581</td>\n      <td>0.486722</td>\n      <td>-0.734377</td>\n      <td>-0.359439</td>\n      <td>-0.515557</td>\n      <td>1</td>\n      <td>19.174109</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.686362</td>\n      <td>0.810403</td>\n      <td>-0.127156</td>\n      <td>0.049691</td>\n      <td>-0.722663</td>\n      <td>1</td>\n      <td>14.096041</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.270678</td>\n      <td>0.418167</td>\n      <td>-0.747838</td>\n      <td>-0.360587</td>\n      <td>-0.447434</td>\n      <td>1</td>\n      <td>18.695078</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>-0.459596</td>\n      <td>-0.513566</td>\n      <td>-0.230339</td>\n      <td>-0.197124</td>\n      <td>-0.142681</td>\n      <td>0</td>\n      <td>11.552031</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0.353899</td>\n      <td>0.330092</td>\n      <td>0.481501</td>\n      <td>0.140985</td>\n      <td>0.080699</td>\n      <td>1</td>\n      <td>2.614529</td>\n      <td>1.803656</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>-0.221661</td>\n      <td>-0.488341</td>\n      <td>0.028726</td>\n      <td>-0.115426</td>\n      <td>-0.013636</td>\n      <td>0</td>\n      <td>8.176119</td>\n      <td>0.698690</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>-0.308154</td>\n      <td>0.301733</td>\n      <td>-0.730905</td>\n      <td>-0.398765</td>\n      <td>-0.322134</td>\n      <td>1</td>\n      <td>17.780859</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0.197770</td>\n      <td>-0.689366</td>\n      <td>0.340792</td>\n      <td>0.040297</td>\n      <td>0.541430</td>\n      <td>0</td>\n      <td>0.337498</td>\n      <td>1.559129</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the latent representations of the data\n",
    "z = encoder.predict(observations.to_numpy()).T\n",
    "data['z_1'] = z[0]\n",
    "data['z_2'] = z[1]\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# style for the plots\n",
    "sns.set_style('white')\n",
    "sns.set_palette('PRGn', 2)\n",
    "sns.scatterplot(data=data, x='z_1', y='z_2', hue='y')\n",
    "plt.savefig('figures/autoencoder_latent_space.png', dpi=250)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder: 0.42\n"
     ]
    }
   ],
   "source": [
    "from representation_learning.metrics import multiple_correlation\n",
    "\n",
    "print(f\"autoencoder: {multiple_correlation(data, 'y', ['z_1', 'z_2']):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder: 0.19\n"
     ]
    }
   ],
   "source": [
    "from representation_learning.metrics import mutual_information_gap\n",
    "\n",
    "print(f\"autoencoder: {mutual_information_gap(data, ['h_1', 'h_2'], ['z_1', 'z_2']):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Range: [0.20000, 5.00000]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eec876abbcad4eef83b1b0ca4db70b0e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: -0.136, New Window Size: 0.73333\n",
      "Search Range: [0.00000, 0.73333]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ba003c1cba347db86529c1bd0d2ae24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: 0.793, New Window Size: 0.16296\n",
      "Search Range: [0.00000, 0.16296]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3c82c7803d84cacb5a8266d7cf82639"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: 0.833, New Window Size: 0.03621\n",
      "Search Range: [0.07243, 0.10864]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12c46411d89443169f16f2f1617852c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: 0.836, New Window Size: 0.00805\n",
      "Search Range: [0.08852, 0.09657]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98bd1209eae643ab82a460dffc9f0a32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: 0.836, New Window Size: 0.00179\n",
      "Search Range: [0.09299, 0.09478]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1a9a972af1d4623b52e366318c719b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Stress: 0.836, New Window Size: 0.00040\n",
      "autoencoder: 0.84\n"
     ]
    }
   ],
   "source": [
    "from representation_learning.metrics import inverted_kruskals_stress\n",
    "\n",
    "print(f\"autoencoder: {inverted_kruskals_stress(data, ['x_1', 'x_2', 'x_3'], ['z_1', 'z_2'], 0.001):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data.to_csv('datasets/encoded_latent.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}