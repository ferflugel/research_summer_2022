{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         review_id  user_id  business_id  stars  useful  funny   cool   text  \\\nquality                                                                        \n0            10000    10000        10000  10000   10000  10000  10000  10000   \n1            10000    10000        10000  10000   10000  10000  10000  10000   \n\n          date  price_range  state  \nquality                             \n0        10000        10000  10000  \n1        10000        10000  10000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n      <th>price_range</th>\n      <th>state</th>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read file with reviews data for restaurants\n",
    "reviews = pd.read_csv('datasets/reviews_restaurants.csv')\n",
    "\n",
    "# filter out restaurants with price range of 2\n",
    "reviews = reviews[reviews['stars'] != 3]\n",
    "\n",
    "# add categories based on price\n",
    "reviews['quality'] = ''\n",
    "reviews.loc[reviews['stars'] <= 2, 'quality'] = 0\n",
    "reviews.loc[reviews['stars'] >= 4, 'quality'] = 1\n",
    "\n",
    "# reduce the dataset to 10000 reviews of each category\n",
    "reviews = reviews.groupby('quality').apply(lambda x: x.sample(10000, random_state=0).reset_index(drop=True))\n",
    "reviews = reviews.droplevel(level=0)\n",
    "\n",
    "# check if the sampling went well\n",
    "reviews.groupby('quality').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# download the glove pre-trained model\n",
    "glove = api.load('glove-twitter-50')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(20000, 50, 50)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from text_representation import get_processed_inputs\n",
    "\n",
    "# processing inputs\n",
    "glove_inputs = get_processed_inputs(reviews, column='text', mode='list_of_lists')\n",
    "\n",
    "# create the word2vec list of vectors\n",
    "glove_array = []\n",
    "\n",
    "for text in glove_inputs:\n",
    "    text_matrix = []\n",
    "    count = 0\n",
    "\n",
    "    if len(text) >= 50:\n",
    "        text = text[:50]\n",
    "        for token in text:\n",
    "            if token in glove:\n",
    "                text_matrix.append(glove[token])\n",
    "            else:\n",
    "                count += 1\n",
    "    else:\n",
    "\n",
    "        for token in text:\n",
    "            if token in glove:\n",
    "                text_matrix.append(glove[token])\n",
    "            else:\n",
    "                count += 1\n",
    "        for i in range(50 - len(text)):\n",
    "            text_matrix.append(np.zeros(50))\n",
    "\n",
    "    for i in range(count):\n",
    "        text_matrix.append(np.zeros(50))\n",
    "\n",
    "    glove_array.append(np.array(text_matrix))\n",
    "\n",
    "glove_array = np.array(glove_array)\n",
    "\n",
    "# check shape\n",
    "glove_array.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 50, 50, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 50, 50, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 25, 25, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 25, 25, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 9, 9, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 9, 9, 8)           584       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 3, 3, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 3, 3, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 9, 9, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 9, 9, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 27, 27, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 25, 25, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 50, 50, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 50, 50, 1)         145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_matrix = keras.Input(shape=(50, 50, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_matrix)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((3, 3), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((3, 3), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (3, 3, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((3, 3))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((3, 3))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_matrix, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "encoder = keras.Model(input_matrix, encoded)\n",
    "\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(15000, 50, 50)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# produce the X and y for training and testing\n",
    "quality = np.array(reviews['quality'].tolist())\n",
    "X_train, X_test, y_train, y_test = train_test_split(glove_array, quality, test_size = 0.25, random_state=0)\n",
    "\n",
    "# check shape of the test set\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "118/118 [==============================] - 36s 309ms/step - loss: -1.2267 - val_loss: -1.2263\n",
      "Epoch 2/15\n",
      "118/118 [==============================] - 32s 270ms/step - loss: -1.2293 - val_loss: -1.2296\n",
      "Epoch 3/15\n",
      "118/118 [==============================] - 33s 279ms/step - loss: -1.2317 - val_loss: -1.2318\n",
      "Epoch 4/15\n",
      "118/118 [==============================] - 29s 242ms/step - loss: -1.2337 - val_loss: -1.2327\n",
      "Epoch 5/15\n",
      "118/118 [==============================] - 20s 168ms/step - loss: -1.2350 - val_loss: -1.2341\n",
      "Epoch 6/15\n",
      "118/118 [==============================] - 24s 203ms/step - loss: -1.2364 - val_loss: -1.2355\n",
      "Epoch 7/15\n",
      "118/118 [==============================] - 21s 181ms/step - loss: -1.2376 - val_loss: -1.2370\n",
      "Epoch 8/15\n",
      "118/118 [==============================] - 18s 156ms/step - loss: -1.2387 - val_loss: -1.2379\n",
      "Epoch 9/15\n",
      "118/118 [==============================] - 18s 156ms/step - loss: -1.2396 - val_loss: -1.2391\n",
      "Epoch 10/15\n",
      "118/118 [==============================] - 26s 217ms/step - loss: -1.2405 - val_loss: -1.2399\n",
      "Epoch 11/15\n",
      "118/118 [==============================] - 19s 165ms/step - loss: -1.2413 - val_loss: -1.2406\n",
      "Epoch 12/15\n",
      "118/118 [==============================] - 19s 161ms/step - loss: -1.2421 - val_loss: -1.2410\n",
      "Epoch 13/15\n",
      "118/118 [==============================] - 26s 224ms/step - loss: -1.2428 - val_loss: -1.2411\n",
      "Epoch 14/15\n",
      "118/118 [==============================] - 27s 232ms/step - loss: -1.2433 - val_loss: -1.2426\n",
      "Epoch 15/15\n",
      "118/118 [==============================] - 21s 180ms/step - loss: -1.2440 - val_loss: -1.2426\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fc6da077e20>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=15,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(15000, 3, 3, 8)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train = encoder.predict(X_train)\n",
    "encoded_test = encoder.predict(X_test)\n",
    "\n",
    "encoded_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "((15000, 72), (5000, 72))"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the matrices for each document in the train set\n",
    "temp = []\n",
    "for encoded_matrix in encoded_train:\n",
    "    temp.append(encoded_matrix.flatten())\n",
    "embedding_train = np.array(temp)\n",
    "\n",
    "# flatten the matrices for each document in the test set\n",
    "temp = []\n",
    "for encoded_matrix in encoded_test:\n",
    "    temp.append(encoded_matrix.flatten())\n",
    "embedding_test = np.array(temp)\n",
    "\n",
    "# check results\n",
    "embedding_train.shape, embedding_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM test score: 0.6814\n",
      "SVM train score: 0.6802666666666667\n",
      "RF test score: 0.6546\n",
      "RF train score: 0.6750666666666667\n",
      "LR test score: 0.7022\n",
      "LR train score: 0.7006666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandoassad/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using SVMs for classification\n",
    "svm = SVC(C=0.5).fit(embedding_train, y_train)\n",
    "print(\"SVM test score:\", svm.score(embedding_test, y_test))\n",
    "print(\"SVM train score:\", svm.score(embedding_train, y_train))\n",
    "\n",
    "# using random forests for classification\n",
    "rfc = RandomForestClassifier(max_depth=5, random_state=0).fit(embedding_train, y_train)\n",
    "print(\"RF test score:\", rfc.score(embedding_test, y_test))\n",
    "print(\"RF train score:\", rfc.score(embedding_train, y_train))\n",
    "\n",
    "# using logistic regression for classification\n",
    "lrc = LogisticRegression(random_state=0, max_iter=125, C=0.5).fit(embedding_train, y_train)\n",
    "print(\"LR test score:\", lrc.score(embedding_test, y_test))\n",
    "print(\"LR train score:\", lrc.score(embedding_train, y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}